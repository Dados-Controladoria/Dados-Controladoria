{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da370a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd3245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Defina o caminho e o padrão de busca\n",
    "CAMINHO_SAIDAS_ETL = r\"C:\\Users\\jea_goncalves\\Desktop\\bases_balancete\\saidas\"\n",
    "padrao_magalu_pkl = \"balancete_magalu_processado_*.pkl\"\n",
    "caminho_busca_magalu = os.path.join(CAMINHO_SAIDAS_ETL, padrao_magalu_pkl)\n",
    "\n",
    "# 2. Encontra todos os arquivos que correspondem ao padrão\n",
    "arquivos_magalu_encontrados = glob.glob(caminho_busca_magalu)\n",
    "\n",
    "# 3. Carrega o arquivo mais recente\n",
    "if arquivos_magalu_encontrados:\n",
    "    # Encontra o caminho do arquivo com a data de modificação mais recente\n",
    "    caminho_recente_magalu = max(arquivos_magalu_encontrados, key=os.path.getmtime)\n",
    "    print(f\"Carregando arquivo encontrado: {os.path.basename(caminho_recente_magalu)}\")\n",
    "    \n",
    "    # Carrega o DataFrame do arquivo pickle\n",
    "    df_magalu = pd.read_pickle(caminho_recente_magalu)\n",
    "    \n",
    "    print(\"DataFrame 'df_magalu' carregado com sucesso.\")\n",
    "    # print(df_magalu.info()) # Descomente para verificar os tipos de dados\n",
    "else:\n",
    "    print(f\"ERRO: Nenhum arquivo encontrado com o padrão '{padrao_magalu_pkl}'\")\n",
    "    df_magalu = pd.DataFrame() # Cria um DataFrame vazio para evitar erros futuros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decfd090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 4: Carregando os Balancetes da Época (.pkl)\n",
    "\n",
    "# (Não precisa reimportar as bibliotecas se já executou a célula anterior)\n",
    "\n",
    "# --- CARREGAR BALANCETE ÉPOCA (MÊS ANTERIOR) ---\n",
    "padrao_epoca_anterior_pkl = \"balancete_epoca_mes_anterior_*.pkl\" # Exemplo de padrão\n",
    "caminho_busca_epoca_ant = os.path.join(CAMINHO_SAIDAS_ETL, padrao_epoca_anterior_pkl)\n",
    "arquivos_epoca_ant_encontrados = glob.glob(caminho_busca_epoca_ant)\n",
    "\n",
    "if arquivos_epoca_ant_encontrados:\n",
    "    caminho_recente_epoca_ant = max(arquivos_epoca_ant_encontrados, key=os.path.getmtime)\n",
    "    print(f\"Carregando arquivo encontrado: {os.path.basename(caminho_recente_epoca_ant)}\")\n",
    "    df_epoca_anterior = pd.read_pickle(caminho_recente_epoca_ant)\n",
    "    print(\"DataFrame 'df_epoca_anterior' carregado com sucesso.\\n\")\n",
    "else:\n",
    "    print(f\"AVISO: Nenhum arquivo encontrado com o padrão '{padrao_epoca_anterior_pkl}'\")\n",
    "    df_epoca_anterior = pd.DataFrame()\n",
    "\n",
    "# --- CARREGAR BALANCETE ÉPOCA (MÊS ATUAL) ---\n",
    "padrao_epoca_atual_pkl = \"balancete_epoca_mes_atual_*.pkl\" # Exemplo de padrão\n",
    "caminho_busca_epoca_atual = os.path.join(CAMINHO_SAIDAS_ETL, padrao_epoca_atual_pkl)\n",
    "arquivos_epoca_atual_encontrados = glob.glob(caminho_busca_epoca_atual)\n",
    "\n",
    "if arquivos_epoca_atual_encontrados:\n",
    "    caminho_recente_epoca_atual = max(arquivos_epoca_atual_encontrados, key=os.path.getmtime)\n",
    "    print(f\"Carregando arquivo encontrado: {os.path.basename(caminho_recente_epoca_atual)}\")\n",
    "    df_epoca_atual = pd.read_pickle(caminho_recente_epoca_atual)\n",
    "    print(\"DataFrame 'df_epoca_atual' carregado com sucesso.\")\n",
    "else:\n",
    "    print(f\"AVISO: Nenhum arquivo encontrado com o padrão '{padrao_epoca_atual_pkl}'\")\n",
    "    df_epoca_atual = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "CAMINHO_CREDENCIAL_JSON = os.getenv('GOOGLE_CREDENTIALS_SERVICE_ACCOUNT')\n",
    "ID_PLANILHA = os.getenv('GOOGLE_SHEET_ID')\n",
    "NOME_ABA  = os.getenv('WORKSHEET_NAME')\n",
    "TOKEN_USER = os.getenv('AUTHORIZED_USER_FILE_PATH')\n",
    "gc = gspread.service_account(\n",
    "    filename=CAMINHO_CREDENCIAL_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = gc.open_by_key(ID_PLANILHA)\n",
    "aba = ws.worksheet(NOME_ABA)\n",
    "data = aba.get_all_records()\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4301e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def get_target_month_strings():\n",
    "    today = datetime(2025,6,1)\n",
    "    # Para consistência com o exemplo \"05-25\", vamos fixar as datas.\n",
    "    # Remova ou ajuste estas linhas para usar datas dinâmicas reais.\n",
    "    # today = datetime(2025, 6, 1) # Exemplo: Mês atual é Junho de 2025\n",
    "\n",
    "    current_month_year_obj = today\n",
    "    previous_month_year_obj = today - relativedelta(months=1)\n",
    "\n",
    "    # Formato MM-AA (ex: \"06-25\", \"05-25\")\n",
    "    current_month_str = current_month_year_obj.strftime(\"%m-%y\")\n",
    "    prev_month_str = previous_month_year_obj.strftime(\"%m-%y\")\n",
    "    return current_month_str, prev_month_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_MONTH_STR, PREV_MONTH_STR = get_target_month_strings()\n",
    "print(f\"Mês Anterior Alvo: {PREV_MONTH_STR}\")\n",
    "print(f\"Mês Atual Alvo: {CURRENT_MONTH_STR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b9218",
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_PERIODO = \"PERIODO\"\n",
    "COL_EMPRESA = \"EMPRESA\"\n",
    "COL_A_FORMULA = \"CONCATENAÇÃO\" # Coluna A da planilha\n",
    "COL_B_BAL1_START = \"LIVRO\" # Exemplo da primeira coluna de dados do Balancete 1\n",
    "# ... adicione outros nomes de coluna do df_sheets se necessário para referência\n",
    "COL_G_BAL2_START_CONTAS = \"CONTA\" # Exemplo da coluna \"Contas\" do Balancete 2 (em G)\n",
    "COL_M_FORMULA = \"MOV_MES\" # Coluna M da planilha\n",
    "\n",
    "# Placeholder para as fórmulas\n",
    "FORMULA_A_PLACEHOLDER = \"=CONCATENAR(F_val,G_val)\" # Exemplo, ajuste para sua fórmula real\n",
    "FORMULA_M_PLACEHOLDER = \"=J_val-K_val\" # Exemplo, ajuste para sua fórmula real\n",
    "\n",
    "# Colunas que são copiadas de cima para baixo no Balancete 2\n",
    "BAL2_COLS_COPIED_DOWN = ['LIVRO', 'DATA_EFETIVA', 'PERIODO', 'EMPRESA']\n",
    "# Assumindo que essas são as colunas B, D, E, F respectivamente, como mencionado.\n",
    "# Seus nomes reais no df_sheets podem ser diferentes.\n",
    "# No exemplo de df_sheets, vou usar nomes genéricos como 'SheetColB', 'SheetColD', etc.\n",
    "# E os balancetes ETL terão colunas com os dados de valor.\n",
    "\n",
    "# --- DEFINA AQUI A ORDEM DAS COLUNAS DO SEU `df_sheets` ---\n",
    "# Isto é crucial para criar novas linhas corretamente.\n",
    "# Substitua pela lista real de colunas da sua planilha.\n",
    "ORDERED_SHEET_COLUMNS = [\n",
    "    COL_A_FORMULA, 'LIVRO', 'ULTIMA_ALTERCAO_GL', 'DATA_EFETIVA', 'PERIODO', 'EMPRESA',\n",
    "    COL_G_BAL2_START_CONTAS, 'DESCRICAO_CONTA', 'SALDO_INICIAL', 'DEBITO', 'CREDITO', 'SALDO_FINAL',\n",
    "    COL_M_FORMULA, COL_PERIODO, COL_EMPRESA\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34017bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sheets = pd.DataFrame(data, columns=ORDERED_SHEET_COLUMNS)\n",
    "# Adicionando uma linha \"header\" B1 simbólica para o index 0, para que B2 seja index 1\n",
    "# A linha B2 da planilha corresponde ao df_sheets.iloc[1] (se não houver header no DataFrame)\n",
    "# Ou df_sheets.loc[2] se o índice começar em 1 e tiver uma linha de header no índice 1.\n",
    "# Para simplificar, vamos assumir que a \"linha B2\" se refere ao df_sheets.iloc[1] para o primeiro bloco de dados.\n",
    "\n",
    "print(\"df_sheets Inicial:\")\n",
    "df_sheets.head(15000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b3cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas de VALOR que serão copiadas do df_bal1 para o df_sheets (a partir da SheetColB)\n",
    "# Estas devem corresponder às colunas em df_sheets de COL_B_BAL1_START em diante.\n",
    "# Ex: 'ValorConta1', 'ValorConta2' irão para 'SheetColB', 'SheetColC'\n",
    "BAL1_ETL_VALUE_COLS = ['ValorConta1_B1', 'ValorConta2_B1', 'ValorConta3_B1', 'ValorConta4_B1', 'ValorConta5_B1', 'ValorConta6_B1', 'ValorConta7_B1', \n",
    "                       'ValorConta8_B1', 'ValorConta9_B1', 'ValorConta10_B1', 'ValorConta11_B1']\n",
    "# O número de colunas em BAL1_ETL_VALUE_COLS deve corresponder ao número de colunas de dados do Bal1 no df_sheets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal1_data = {\n",
    "    COL_PERIODO: [PREV_MONTH_STR, PREV_MONTH_STR, PREV_MONTH_STR, CURRENT_MONTH_STR],\n",
    "    COL_EMPRESA: ['1', '1', '1', '1'], # Balancete 1 sempre tem empresa <> '2' (ex: '1')\n",
    "    'ValorConta1_B1': [10, 20, 25, 30],\n",
    "    'ValorConta2_B1': [11, 21, 26, 31],\n",
    "    'ValorConta3_B1': [12, 22, 27, 32],\n",
    "    'ValorConta4_B1': [13, 23, 28, 33],\n",
    "    'ValorConta5_B1': [14, 24, 29, 34],\n",
    "    'ValorConta6_B1': [15, 25, 30, 35],\n",
    "    'ValorConta7_B1': [16, 26, 31, 36],\n",
    "    'ValorConta8_B1': [17, 27, 32, 37],\n",
    "    'ValorConta9_B1': [18, 28, 33, 38],\n",
    "    'ValorConta10_B1': [19, 29, 34, 39],\n",
    "    'ValorConta11_B1': [20, 30, 35, 40]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal1 = pd.DataFrame(df_bal1_data)\n",
    "print(\"\\ndf_bal1 (ETL):\")\n",
    "print(df_bal1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1441cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: df_bal2_prev_month (Balancete 2 - Mês Anterior)\n",
    "# Colunas de VALOR que serão copiadas do df_bal2 para o df_sheets (a partir de COL_G_BAL2_START_CONTAS)\n",
    "BAL2_ETL_VALUE_COLS = ['Contas_B2', 'Val2_B2', 'Val3_B2', 'Val4_B2', 'Val5_B2', 'Val6_B2']\n",
    "# O número de colunas em BAL2_ETL_VALUE_COLS deve corresponder ao número de colunas de dados do Bal2 no df_sheets (G em diante)\n",
    "\n",
    "\n",
    "\n",
    "df_bal2_prev_data = {\n",
    "    COL_PERIODO: [PREV_MONTH_STR],\n",
    "    COL_EMPRESA: ['2'], # Balancete 2 sempre tem empresa '2'\n",
    "    'Contas_B2': [600], # Vai para COL_G_BAL2_START_CONTAS\n",
    "    'Val2_B2': [60],    # Vai para SheetColH\n",
    "    'Val3_B2': [61],\n",
    "    'Val4_B2': [62],\n",
    "    'Val5_B2': [63],\n",
    "    'Val6_B2': [64]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d288ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal2_prev_month = pd.DataFrame(df_bal2_prev_data)\n",
    "print(\"\\ndf_bal2_prev_month (ETL):\")\n",
    "print(df_bal2_prev_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a23892",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAL2_SHEET_COLS_COPIED_DOWN = ['SheetColB', 'SheetColD', 'SheetColE', 'SheetColF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda07d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_sheet_section(\n",
    "    df_main_sheet,\n",
    "    etl_data_for_period,\n",
    "    target_period,\n",
    "    is_bal_type_1, # True para Balancete 1, False para Balancete 2\n",
    "    ordered_sheet_cols, # Lista com todos os nomes de coluna do df_sheets na ordem correta\n",
    "    bal1_etl_val_cols, # Lista de colunas do ETL Bal1 a serem coladas\n",
    "    bal1_sheet_start_col_name, # Nome da coluna no df_sheets onde começam os dados do Bal1 (ex: 'SheetColB')\n",
    "    bal2_etl_val_cols, # Lista de colunas do ETL Bal2 a serem coladas\n",
    "    bal2_sheet_start_col_name, # Nome da coluna no df_sheets onde começam os dados do Bal2 (ex: 'SheetColG_Contas')\n",
    "    bal2_sheet_cols_to_copy_down # Lista de colunas no df_sheets a serem copiadas de cima para baixo para Bal2\n",
    "):\n",
    "    print(f\"\\n--- Processando: {'Balancete 1' if is_bal_type_1 else 'Balancete 2'} para o período {target_period} ---\")\n",
    "     # Garantir que o DataFrame principal tenha um índice resetado se não for RangeIndex\n",
    "    # Isso pode ser necessário se houver exclusões e concatenações frequentes.\n",
    "    # No entanto, para inserções e deleções usando iloc/loc e concat, o pandas geralmente lida bem,\n",
    "    # mas é bom ter cuidado se os índices ficarem não sequenciais.\n",
    "    # df_main_sheet = df_main_sheet.reset_index(drop=True) # Descomente se necessário\n",
    "\n",
    "    # 1. Identificar o bloco existente no df_sheets\n",
    "    if is_bal_type_1:\n",
    "        sheet_block_filter = (df_main_sheet[COL_PERIODO] == target_period) & (df_main_sheet[COL_EMPRESA] != '2')\n",
    "    else: # Balancete 2\n",
    "        sheet_block_filter = (df_main_sheet[COL_PERIODO] == target_period) & (df_main_sheet[COL_EMPRESA] == '2')\n",
    "\n",
    "    current_block_indices = df_main_sheet[sheet_block_filter].index\n",
    "    num_sheet_rows = len(current_block_indices)\n",
    "    num_etl_rows = len(etl_data_for_period)\n",
    "\n",
    "    print(f\"Linhas existentes no df_sheets para este bloco: {num_sheet_rows}\")\n",
    "    print(f\"Linhas no ETL para este bloco: {num_etl_rows}\")\n",
    "\n",
    "     # Determinar o ponto de partida para colar os dados do ETL\n",
    "    if is_bal_type_1:\n",
    "        sheet_cols_to_paste_into = ordered_sheet_cols[ordered_sheet_cols.index(bal1_sheet_start_col_name) : ordered_sheet_cols.index(bal1_sheet_start_col_name) + len(bal1_etl_val_cols)]\n",
    "        etl_value_cols = bal1_etl_val_cols\n",
    "    else: # Balancete 2\n",
    "        sheet_cols_to_paste_into = ordered_sheet_cols[ordered_sheet_cols.index(bal2_sheet_start_col_name) : ordered_sheet_cols.index(bal2_sheet_start_col_name) + len(bal2_etl_val_cols)]\n",
    "        etl_value_cols = bal2_etl_val_cols\n",
    "\n",
    "\n",
    "    if num_etl_rows == 0 and num_sheet_rows > 0: # Apagar todas as linhas do bloco\n",
    "        print(f\"ETL vazio, apagando {num_sheet_rows} linhas do bloco no df_sheets.\")\n",
    "        df_main_sheet = df_main_sheet.drop(current_block_indices).reset_index(drop=True)\n",
    "        return df_main_sheet\n",
    "\n",
    "    if num_etl_rows == 0 and num_sheet_rows == 0: # Nada a fazer\n",
    "        print(\"Nada no ETL e nada no df_sheets para este bloco. Nenhuma ação.\")\n",
    "        return df_main_sheet\n",
    "    # 2. Ajustar o número de linhas no df_sheets\n",
    "    temp_df_main_sheet = df_main_sheet.copy() # Trabalhar em uma cópia para concatenação\n",
    "\n",
    "    if num_sheet_rows < num_etl_rows: # Adicionar linhas\n",
    "        rows_to_add_count = num_etl_rows - num_sheet_rows\n",
    "        print(f\"Adicionando {rows_to_add_count} linhas ao df_sheets.\")\n",
    "        new_rows_list = []\n",
    "        for _ in range(rows_to_add_count):\n",
    "            new_row_data = {col: np.nan for col in ordered_sheet_cols} # Começa com NaNs\n",
    "            new_row_data[COL_PERIODO] = target_period\n",
    "            new_row_data[COL_EMPRESA] = '1' if is_bal_type_1 else '2'\n",
    "            new_row_data[COL_A_FORMULA] = FORMULA_A_PLACEHOLDER\n",
    "            if not is_bal_type_1:\n",
    "                new_row_data[COL_M_FORMULA] = FORMULA_M_PLACEHOLDER\n",
    "            new_rows_list.append(new_row_data)\n",
    "        new_rows_df = pd.DataFrame(new_rows_list, columns=ordered_sheet_cols)\n",
    "\n",
    "        if not current_block_indices.empty: # Se o bloco existe, adiciona após ele\n",
    "            insert_point_idx = current_block_indices.max() + 1\n",
    "            temp_df_main_sheet = pd.concat([\n",
    "                temp_df_main_sheet.iloc[:insert_point_idx],\n",
    "                new_rows_df,\n",
    "                temp_df_main_sheet.iloc[insert_point_idx:]\n",
    "            ]).reset_index(drop=True)\n",
    "        else: # Bloco não existe, precisa encontrar onde inserir (lógica complexa de ordenação global)\n",
    "              # Para este exemplo, vamos assumir que se o bloco não existe, ele é anexado ao final do período\n",
    "              # ou em uma ordem específica (B1 antes de B2 do mesmo período, Período Anterior antes de Atual).\n",
    "              # Esta parte da lógica de inserção de um *novo bloco inteiro* em um local específico\n",
    "              # precisaria de mais regras sobre a ordem global dos blocos.\n",
    "              # Por ora, se um bloco estiver faltando, esta função vai anexá-lo de forma simples,\n",
    "              # o que pode não ser a ordem visual correta na planilha.\n",
    "              # A melhor abordagem é que `df_sheets` já tenha pelo menos uma linha dummy para cada bloco.\n",
    "            print(f\"AVISO: Bloco para {'Bal1' if is_bal_type_1 else 'Bal2'} {target_period} não encontrado. Anexando novas linhas.\")\n",
    "            # Tenta encontrar o final do período anterior ou do balancete anterior no mesmo período\n",
    "            # Esta é uma simplificação e pode precisar de ajuste fino.\n",
    "            relevant_period_data = temp_df_main_sheet[temp_df_main_sheet[COL_PERIODO] == target_period]\n",
    "            if not relevant_period_data.empty:\n",
    "                insert_point_idx = relevant_period_data.index.max() + 1\n",
    "                temp_df_main_sheet = pd.concat([\n",
    "                    temp_df_main_sheet.iloc[:insert_point_idx],\n",
    "                    new_rows_df,\n",
    "                    temp_df_main_sheet.iloc[insert_point_idx:]\n",
    "                ]).reset_index(drop=True)\n",
    "            else: # Se nem o período existe, anexa ao final\n",
    "                 temp_df_main_sheet = pd.concat([temp_df_main_sheet, new_rows_df]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    elif num_sheet_rows > num_etl_rows: # Deletar linhas\n",
    "        rows_to_delete_count = num_sheet_rows - num_etl_rows\n",
    "        print(f\"Deletando {rows_to_delete_count} linhas do df_sheets.\")\n",
    "        # Deleta as últimas linhas excedentes do bloco\n",
    "        indices_to_drop = current_block_indices[-rows_to_delete_count:]\n",
    "        temp_df_main_sheet = temp_df_main_sheet.drop(indices_to_drop).reset_index(drop=True)\n",
    "\n",
    "    # Re-identificar o bloco após ajustes de tamanho\n",
    "    if is_bal_type_1:\n",
    "        final_block_filter = (temp_df_main_sheet[COL_PERIODO] == target_period) & (temp_df_main_sheet[COL_EMPRESA] != '2')\n",
    "    else:\n",
    "        final_block_filter = (temp_df_main_sheet[COL_PERIODO] == target_period) & (temp_df_main_sheet[COL_EMPRESA] == '2')\n",
    "    final_block_indices = temp_df_main_sheet[final_block_filter].index\n",
    "\n",
    "    # Garantir que temos o número certo de índices para os dados do ETL\n",
    "    if len(final_block_indices) != num_etl_rows:\n",
    "        print(f\"ERRO: Discrepância no tamanho do bloco final. Esperado: {num_etl_rows}, Obtido: {len(final_block_indices)}\")\n",
    "        # Isso pode acontecer se a lógica de inserção/deleção não funcionar como esperado\n",
    "        # ou se o bloco não existir e a inserção anexa simples não for adequada.\n",
    "        # Por segurança, retorna o DataFrame sem colar os dados se houver essa discrepância.\n",
    "        return df_main_sheet # Retorna o original se algo deu muito errado\n",
    "\n",
    "    # 3. Colar os dados do ETL\n",
    "    print(f\"Colando dados do ETL no bloco final (índices: {final_block_indices.tolist()}).\")\n",
    "    if not etl_data_for_period.empty and not final_block_indices.empty:\n",
    "        for i, etl_col_name in enumerate(etl_value_cols):\n",
    "            sheet_col_name = sheet_cols_to_paste_into[i]\n",
    "            # Usar .values para evitar problemas de alinhamento de índice ao atribuir\n",
    "            temp_df_main_sheet.loc[final_block_indices, sheet_col_name] = etl_data_for_period[etl_col_name].values\n",
    "\n",
    "        # Preencher fórmulas novamente para todas as linhas do bloco final\n",
    "        temp_df_main_sheet.loc[final_block_indices, COL_A_FORMULA] = FORMULA_A_PLACEHOLDER\n",
    "        if not is_bal_type_1: # Balancete 2\n",
    "            temp_df_main_sheet.loc[final_block_indices, COL_M_FORMULA] = FORMULA_M_PLACEHOLDER\n",
    "            # Copiar valores das colunas B, D, E, F de cima para baixo DENTRO do bloco Bal2\n",
    "            if not final_block_indices.empty and bal2_sheet_cols_to_copy_down:\n",
    "                first_row_idx_in_block = final_block_indices.min()\n",
    "                for idx in final_block_indices:\n",
    "                    if idx == first_row_idx_in_block:\n",
    "                        # Para a primeira linha do bloco Bal2, precisamos de uma fonte para B,D,E,F.\n",
    "                        # Se este bloco foi recém-criado ou a linha acima não é Bal2 do mesmo período,\n",
    "                        # esta lógica pode precisar de ajuste.\n",
    "                        # Assumindo que se há uma linha acima (idx-1) ela pode ser uma fonte válida\n",
    "                        # ou os valores já estão corretos por inserção anterior.\n",
    "                        if idx > 0: # Se não for a primeira linha absoluta do DataFrame\n",
    "                             # Tenta copiar da linha imediatamente acima, se essa linha não fizer parte do bloco atual\n",
    "                             # e tiver os mesmos valores de período (ou se for para copiar de qualquer forma).\n",
    "                             # Esta é uma simplificação. A fonte para a primeira linha de um bloco Bal2\n",
    "                             # se as colunas B,D,E,F não estiverem no ETL é um ponto crítico.\n",
    "                             # Se o bloco já existia, a primeira linha do bloco mantém seus valores.\n",
    "                             # Se foi uma nova linha adicionada no início do bloco Bal2,\n",
    "                             # ela deveria idealmente herdar da última linha do bloco Bal1 do mesmo período,\n",
    "                             # ou ter valores padrão.\n",
    "                             # A lógica atual de inserção de new_rows_df já preenche com NaN.\n",
    "                             # Vamos assumir que a primeira linha do bloco já tem, ou deveria ter, os valores corretos de B,D,E,F\n",
    "                             # e a cópia é para as linhas *subsequentes dentro do bloco*.\n",
    "                             pass # A primeira linha do bloco mantém ou obtém seus valores de B,D,E,F de outra forma.\n",
    "                    else: # Para as demais linhas do bloco, copia da linha de cima DENTRO do bloco.\n",
    "                        temp_df_main_sheet.loc[idx, bal2_sheet_cols_to_copy_down] = temp_df_main_sheet.loc[idx-1, bal2_sheet_cols_to_copy_down].values\n",
    "    else:\n",
    "        print(\"Dados do ETL vazios ou bloco final no df_sheets não encontrado/vazio. Nenhuma colagem de dados.\")\n",
    "\n",
    "    return temp_df_main_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3790bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PASSO 1: Balancete 1 - Mês Anterior ---\n",
    "etl_bal1_prev = df_bal1[df_bal1[COL_PERIODO] == PREV_MONTH_STR]\n",
    "df_sheets = update_sheet_section(\n",
    "    df_sheets,\n",
    "    etl_bal1_prev,\n",
    "    PREV_MONTH_STR,\n",
    "    is_bal_type_1=True,\n",
    "    ordered_sheet_cols=ORDERED_SHEET_COLUMNS,\n",
    "    bal1_etl_val_cols=BAL1_ETL_VALUE_COLS,\n",
    "    bal1_sheet_start_col_name='SheetColB', # Primeira coluna de dados do Bal1 no df_sheets\n",
    "    bal2_etl_val_cols=None, # Não aplicável\n",
    "    bal2_sheet_start_col_name=None, # Não aplicável\n",
    "    bal2_sheet_cols_to_copy_down=None # Não aplicável\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd299d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDF_SHEETS após Balancete 1 - Mês Anterior:\")\n",
    "print(df_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PASSO 2: Balancete 2 - Mês Anterior ---\n",
    "etl_bal2_prev = df_bal2_prev_month[df_bal2_prev_month[COL_PERIODO] == PREV_MONTH_STR] # Já filtrado, mas para garantir\n",
    "df_sheets = update_sheet_section(\n",
    "    df_sheets,\n",
    "    etl_bal2_prev,\n",
    "    PREV_MONTH_STR,\n",
    "    is_bal_type_1=False,\n",
    "    ordered_sheet_cols=ORDERED_SHEET_COLUMNS,\n",
    "    bal1_etl_val_cols=None, # Não aplicável\n",
    "    bal1_sheet_start_col_name=None, # Não aplicável\n",
    "    bal2_etl_val_cols=BAL2_ETL_VALUE_COLS,\n",
    "    bal2_sheet_start_col_name=COL_G_BAL2_START_CONTAS, # Coluna 'Contas' do Bal2 no df_sheets\n",
    "    bal2_sheet_cols_to_copy_down=BAL2_SHEET_COLS_COPIED_DOWN\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDF_SHEETS após Balancete 2 - Mês Anterior:\")\n",
    "print(df_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_bal1_curr = df_bal1[df_bal1[COL_PERIODO] == CURRENT_MONTH_STR]\n",
    "df_sheets = update_sheet_section(\n",
    "    df_sheets,\n",
    "    etl_bal1_curr,\n",
    "    CURRENT_MONTH_STR,\n",
    "    is_bal_type_1=True,\n",
    "    ordered_sheet_cols=ORDERED_SHEET_COLUMNS,\n",
    "    bal1_etl_val_cols=BAL1_ETL_VALUE_COLS,\n",
    "    bal1_sheet_start_col_name='SheetColB',\n",
    "    bal2_etl_val_cols=None,\n",
    "    bal2_sheet_start_col_name=None,\n",
    "    bal2_sheet_cols_to_copy_down=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b0ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDF_SHEETS após Balancete 1 - Mês Atual:\")\n",
    "print(df_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_bal2_curr = df_bal2_curr_month[df_bal2_curr_month[COL_PERIODO] == CURRENT_MONTH_STR] # Já filtrado, mas para garantir\n",
    "df_sheets = update_sheet_section(\n",
    "    df_sheets,\n",
    "    etl_bal2_curr,\n",
    "    CURRENT_MONTH_STR,\n",
    "    is_bal_type_1=False,\n",
    "    ordered_sheet_cols=ORDERED_SHEET_COLUMNS,\n",
    "    bal1_etl_val_cols=None,\n",
    "    bal1_sheet_start_col_name=None,\n",
    "    bal2_etl_val_cols=BAL2_ETL_VALUE_COLS,\n",
    "    bal2_sheet_start_col_name=COL_G_BAL2_START_CONTAS,\n",
    "    bal2_sheet_cols_to_copy_down=BAL2_SHEET_COLS_COPIED_DOWN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b882b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDF_SHEETS após Balancete 2 - Mês Atual (FINAL):\")\n",
    "print(df_sheets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atualiza_balancete_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
